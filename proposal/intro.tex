% !TEX root = proposal.tex
\section{Introduction} \label{sec:intro}

Protecting software system from arbitrary attack or developer mistakes is a
challenging task.
%
One promising approach that gains attention from both industry and research
community is the technology of data flow tracking (DFT) that is implemented by
inlining monitoring/protection logic along with the original program's
execution.
%
Well understood for its effectiveness/usefulness for its wide range of
application domain which includes hardening software system against such
security threats~\cite{taintcheck:ndss2005,vigilante:sosp05}, detection of
privacy leakage~\cite{taintdroid:osdi10}, malware analysis~\cite{panorama:ccs2007}, and performance
tuning~\cite{x}, the issue of high overhead is the main obstacle that hinders
its adoptation to production system.
%
For a last a few years, I have focused on addressing the issue of high overhead
for the technology, more apparent when it is applied against unknown binaries
running from commodity system to guarantee full coverage of system protection.

%
% Previous work begins.
%
{\bf \libdft}~\cite{libdft}: it is our initial system that implementation of
DFT. Even though it takes the conventional implementation approach that inserts
tracking operation per instruction basis leveraging VM-based
instrumentation~\cite{pin:pldi2005}, it shows reasonable performance result
thanks to the following design and engineering choices. Firstly, it carefully
crafts tracking logics so as its size not to exceed threshold instruction
count. Secondly, shadow memory is designed to reduce the memory translation
cost.

{\bf \tfafull (\tfa)}~\cite{tfa:ndss2012}: As I noted previously, typical DFT
system interleaves the original execution and DFT logics into a single
execution unit.  Having them decoupled, \tfa optimized DFT logic aggressively
leveraging off-line static analysis dedicated to perform DFT-specific
optimization in consideration of global context.

{\bf ShadowReplica}~\cite{sreplica:ccs2013}: Extending \tfa approach further,
\sreplica executes decoupled logics in parallel from different core along with
the application thread. In this execution model, the main challenge lies in
addressing the issue of high communication overhead needed to transfer
information from the application thread to the thread that performs DFT
analysis. The system addresses the issue by first defining the minimal subset
state from the original execution and then inventing and applying optimizations
that compress the information aggressively. As a result, the system reduces per
basic block(BBL) message requirement from 4.81 to 1.2 contributing to achieves
$\times 2.75$ slowdown over native execution when it is evaluated for SPEC 2006
CPU benchmark.

%
% Hypothesis begins.
%
Given that \sreplica proposes the optimal representation to define and compress
information to be transferred from the application and establish parallelized
DFT analysis, the first hypothesis to be verified is that \sreplica's
communication approach can be generalized to support other families of inline
monitors~\cite{CAB} still minimizing communication volume and
frequency.

To verify the applicability \sreplica's parallelization approach, we build an
overhead modeling framework that categorizes cadidate inline monitors into one
of the following types.

\begin{itemize}

    \item {\bf Inlining model}: Inline monitor shows the best response time
            when the monitoring logic is interleaved with the application
            thread.

    \item {\bf 1-1 model}: Inline monitor shows the best response time when an
            analysis thread is assigned to each application thread. This model
            is similar to produce consumer model.

    \item {\bf 1-n model}: Inline monitor shows the best response time when
            more than one analysis threads are assigned to each application
            thread.  This model requires dedicated dispatcher thread for
            scheduling.
    \end{itemize}

For example, \sreplica, a parallelization framework for DFT,  falls into the
second category (1-1 model) which means that it shows the best response time
when it uses one analysis thread per each analysis thread. Likewise, different
monitors fit into different overhead models. The hypothesis in this case is
that the overhead model would introduce a methodology to choose execution model
for best response time analytically having with a level of confidence high
enough.
 
Lastly, given that the most of inline monitors for binary resort to VM-based
instrumentation framework to collect relevant events from the application
thread, I will confirm that we can implement the same parallelization approach
with different instrumentation mediums and would show different performance
semantics with different instrumentation mediums. Candidates for this substrate
include {\it i)} dynamic binary instrumentation frameworks~(DBI), {\it ii)}
other type of software tracing approach such as DTrace~\cite{DTrace} and {\it
iii)} hardware assisted parallel analysis~\cite{lba}.

Rest of document is organized as follow. Relevant relate work and my own
previous research output that lead to this proposal are discussed from
Section~\ref{sec:related}, and the details of hypotheses follows in
Section~\ref{sec:hypo}. Section~\ref{sec:eval} discusses about evaluation
approaches and Section~\ref{sec:plan} talks about research roadmap to fulfill
the proposal.

