% !TEX root = proposal.tex
\section{Introduction} \label{sec:intro}

Protecting software system from arbitrary attack or developer mistakes is a
challenging task.
%
One promising approach that gains attention from both industry and research
community is the technology of data flow tracking (DFT) that is implemented by
inlining monitoring/protection logic along with the original program's
execution.
%
Well understood for its effectiveness/usefulness for its wide range of
application domain which includes hardening software system against such
security threats~\cite{x}, detection of privacy leakage~\cite{x}, malware
analysis~\cite{x}, and performance tuning~\cite{x}, the issue of high overhead
is the main obstacle that hinders its adoptation to production system.
%
For a last a few years, I have focused on addressing the issue of high overhead
for the technology, more apparent when it is applied against unknown binaries
running from commodity system to guarantee full coverage of system protection.

%
% Previous work begins.
%
{\bf \libdft}~\cite{libdft}: it is our initial system that implementation of
DFT. Even though it takes the conventional implementation approach that inserts
tracking operation per instruction basis leveraging VM-based
instrumentation~\cite{pin:pldi2005}, it shows reasonable performance result
thanks to the following design and engineering choices. Firstly, it carefully
crafts tracking logics so as its size not to exceed threshold instruction
count. Secondly, shadow memory is designed to reduce the memory translation
cost.

{\bf \tfafull (\tfa)}~\cite{tfa:ndss2012}: As I noted previously, typical DFT
system interleaves the original execution and DFT logics into a single
execution unit.  Having them decoupled, \tfa optimized DFT logic aggressively
leveraging off-line static analysis dedicated to perform DFT-specific
optimization in consideration of global context.

{\bf ShadowReplica}~\cite{sreplica:ccs2013}: Extending \tfa approach further,
\sreplica executes decoupled logics in parallel from different core along with
the application thread. In this execution model, the main challenge lies in
addressing the issue of high communication overhead needed to transfer
information from the application thread to the thread that performs DFT
analysis. The system addresses the issue by first defining the minimal subset
state from the original execution and then inventing and applying optimizations
that compress the information aggressively. As a result, the system reduces per
basic block(BBL) message requirement from 4.81 to 1.2 contributing to achieves
$\times 2.75$ slowdown over native execution when it is evaluated for SPEC 2006
CPU benchmark.

%
% Hypothesis begins.
%
Given that \sreplica proposes the optimal representation to define and compress
information to be transferred from the application and establish parallelized
DFT analysis, the first hypothesis to be verified is that \sreplica's
communication approach can be generalized to support other families of inline
monitors~\cite{cfi, memcheck} still minimizing communication volume and
frequency.

Secondly, among many candidate inline monitors to be considered, so as to
verify the applicability \sreplica's parallelization approach, we an overhead
modeling framework that categorizes inline monitors into one of the following
categories.

\begin{itemize}

    \item {\bf Inlining model}: Inline monitor shows the best response time
            when the monitoring logic is interleaved with the application
            thread.

    \item {\bf 1-1 model}: Inline monitor shows the best response time when an
            analysis thread is assigned to each application thread. This model
            is similar to produce consumer model.

    \item {\bf 1-n model}: Inline monitor shows the best response time when
            more than one analysis threads are assigned to each application
            thread.  This model requires dedicated dispatcher thread for
            scheduling.
    \end{itemize}

For example, \sreplica, a parallelization framework for DFT,  falls into the
second category (1-1 model) which means that it shows the best response time
when it uses one analysis thread per each analysis thread. Likewise, different
monitors fit into different overhead models. The hypothesis in this case is
that the overhead model would introduce a methodology to choose execution model
for best response time analytically having with a level of confidence high
enough.
 
Lastly, given that the most of inline monitors for binary resort to VM-based
instrumentation framework to collect relevant events from the application
thread, I will confirm that we can implement the same parallelization approach
with different instrumentation mediums and would show different performance
semantics with different instrumentation mediums. Candidates for this substrate
include {\it i)} dynamic binary instrumentation frameworks~(DBI), {\it ii)}
other type of software tracing approach, and {\it iii)} hardware assisted
profiling and information transfer.


Rest of document is organized as follow.


%However the approach suffers from excessive amount of slowdown and the sources
%for the overhead are {\it i)} instrumentation cost needed to maintain two
%different contexts {\it ii)} cycles for defense/monitoring logic itself.
%%
%
%The idea of parallel analysis that decouples the original application and
%analysis logics and executes these contexts from different execution
%units~(threads) has risen from past research to minimize the runtime overhead. 
%%
%We have two different approaches based on process replication and subset state
%propagation.
%%
%The cost for the communication connecting two threads tends to be too
%high/excessive for both approaches, subsequently masks/overwhelms/cancels the
%parallelization benefit and often make it slower than comparable in-lined
%analysis. Its side-effects include
%
%\begin{itemize} \item n analyzer threads. \item synchronization becomes too
%difficult. \item not suitable for online/runtime analysis. In turn, some are
%purely positioned themselves as an off-line solution. \end{itemize}
%
%%Preliminary result -- explain ShadowReplica, TFA, libdft
%From my previous research~\cite{ShadowReplica, TFA, libdft}, I proposed a
%system that directly addresses the issue of too high communication overhead for
%an analysis of Data Flow Tracking~(DFT). The system first defines minimal but
%necessary representations from the original execution which are {\it i)}
%control flow record in terms of Basic Blocks~(BBL) and {\it ii)} effective
%address~(EA) touched from each BBL. Then I established a framework that applies
%number of optimizations that compress both the frequency and the amount of the
%communication requirement at runtime. 
%%
%These informations are transferred via/using carefully crafted communication
%channel in consideration of/specific to underlying CPU architectures. Its
%design is deeply related to various aspects such as size of on-chip caches and
%thread and CPU affinities.
%%
%In turn, the system could achieve {\it i)} minimize the mitigation of event
%collection to the original execution, {\it ii)} minimize the communication
%traffic, and {\it iii)} make the analysis thread run faster than the original
%thread.
%%
%1.2 messages per BBL, $\sim$ 2.75 $\times$
%
%%what this proposal is about.
%From this proposal, I aim to generalize my previous research to invent a
%(general) methodology that would accelerates the decoupled analysis that
%implements/replaces/substitutes in-line monitors of certain categories.
%\jikk{number agreement problem.}
%%"our hypothesis is that the use of XYZ technology in environment Z under
%%constraints Q can identify insider attackers with probability Z" 
%%
%Our hypothesis is that with two elements~(CFR, EAs) collected from the original
%execution, that I previously defined for \SR, the monitoring logics can
%correctly be reconstructed from separate execution unit(s) for most of in-lined
%analysis. Leveraging/applying (analysis-agnostic) optimization approaches
%invented for \SR, these monitoring logics along with the their original
%executions can have performance gain as DFT did for \SR.
%
%%
%I provide a framework to categorize unknown/arbitrary in-line
%monitors~\cite{CAB} and eventually make the applicability decision.
%%
%For this, I define number of abstractions and requirements shared among in-line
%monitors which, in turn, would help in defining/designing common API for users
%to implement arbitrary parallelized analysis.
%%
%I go over \SR optimizations mostly designed to minimize the frequency and the
%amount of communication requirement. While most of these are general
%optimizations applicable to most of monitoring logics, it also have a few that
%only applicable to specific type of analysis.
%
%I plan to verify aforementioned hypothesis in number of ways listed from below.
%
%The generalization idea will be verified by implementing number of different
%analysis~\cite{memcheck, cfi} applying the approach.
%%
%\SR's communication channel design will be generalized to support custom
%analysis.
%%
%I will explore another design space leveraging the minimal data representation.
%One direction that I am working on is about leveraging hardware component that
%would replace the expensive operations from VM-based instrumentation; event
%collecting and communication component.
%
%% I may want to say something about the optimality of the approach to be
%% verified formally.
%
%% Novelty, if it is properly implemented/fulfilled.
%In this proposal, I define minimal but sufficient representation required to
%offload custom monitoring logics from the original execution at runtime. Once
%it is properly defined, research as well as industry can take advantage of it
%to make known-to-be expensive security measures more widely/generally adopted.
%%
%This innovation eventually result in reducing to size of trusted computing
%base~(TCB) required to implement custom in-line analysis only with reasonable
%amount of overhead would in turn impact on many areas hardware based
%implementation, mobile security, and cloud computing. 
