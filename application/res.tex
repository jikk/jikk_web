\documentclass[letterpaper, 10pt]{article}
\topmargin-2.0cm
 
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{xspace}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

% Color Information from -
% http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/latex_advanced/node13.html

\advance\oddsidemargin-0.65in
\advance\evensidemargin-1.5cm
\textheight9.2in
\textwidth6.75in
\newcommand\bb[1]{\mbox{\em #1}}
\def\baselinestretch{1.05}

\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}

\begin{document}
\thispagestyle{fancy}

% Leave Left and Right Header empty.
\lhead{}
\rhead{}

\renewcommand{\headrulewidth}{0pt} \renewcommand{\footrulewidth}{0pt}
\fancyfoot[C]{\footnotesize
\textcolor{gray}{http://www.cs.columbia.edu/$\sim$jikk/application}}

\pagestyle{fancy}
\lhead{\textcolor{gray}{\it Kangkook Jee}}
\rhead{\textcolor{gray}{\thepage /\pageref{LastPage}}}

%Macros of my own
\def\libdft{libdft\xspace}
\def\TFAFull{Taint Flow Algebra\xspace}
\def\TFA{TFA\xspace}
\def\SR{ShadowReplica\xspace}
\def \ie{i.e.,\xspace}

\newif \ifcomments
\commentstrue

\ifcomments
\newcommand{\jikk}[1]{{---\textcolor{red}{#1}---}}
\else
\newcommand{\jikk}[1]{}
\fi
%

% This kind of makes 10pt to 9 pt.
\begin{small}

%\vspace*{0.1cm}
\begin{center}
{\LARGE \bf RESEARCH STATEMENT}\\
\vspace*{0.1cm}
{\normalsize Kangkook Jee (jikk@cs.columbia.edu)}
\end{center}
%\vspace*{0.2cm}

%\begin{document}
%\centerline {\Large \bf Research Statement for Kangkook Jee}
%\vspace{0.5cm}

% Write about research interests...
%\footnotemark
%\footnotetext{Check This}

% Say that research work has been both theoretical and practical.
My long-term research interest lies in {\it i)} building security systems that
protect/harden unknown software program making it immune to software failures
caused either by active exploitation of malicious attackers or by invocation of
unintended developer bugs and {\it ii)} making these technologies practical,
suitable for production deployment by addressing the issue of high overhead.
%
To achieve the goal of building reliable software and make it practical, I
leverages recent innovations from different software substrates which encompass
static and dynamic approaches. Specifically, throughout my research history, I
have been interested in combining those two approaches to address the high
overhead problem. 
%
Although, my main research contributions are concretized in the course of
developing and improving well-known security system of data flow
tracking~(DFT), the system has many architectural characteristics common to
else security systems.  Thus, I believe that wisdoms/insights I learned from
the stream of research is generic enough to be applied to the area of system
security in general. \jikk{this statement should be refined further.}
%
I am also interested in other techniques related to software reliability which
include whitebox/blackbox fuzzing and building a system that defends against
integer error. 

\subsection*{Data Flow Tracking(DFT) systems} 
% Paragraph 1: A brief paragraph sketching the overarching thematics and topic
% of your research, situating it disciplinary.
%
In my research history, I extensively explored various aspects of DFT systems
for its effectiveness in serving many different areas of
research~\cite{libdft:2012vee, tfa:2012ndss, sreplica:2013ccs} as well as
making it efficient so that it can more be adopted by users who want to use the
technology.
%
Typical DFT system composed of three different types of operations {\it i)}
tagging untrusted inputs {\it ii)} propagating tag values associated to
variables(memory locations) along with program executions {\it iii)} checking
for unintended usages of tagged data. Our implementations in-lines these
operations using VM-based instrumentation framework so that we can apply it to
COTS binaries making us achieving complete coverage.
%
Besides implementing DFT system that accurately operates, I have been invented
number of techniques to resolve the high overhead issue known to inherent to
tools based on VM-based instrumentation and this is where one can find my core
research contributions.

% libdft
\subsubsection*{\libdft: Fine grained DFT system for COTS binaries}
With respect to the number of DFT related research outputs, we first
implemented \libdft~\cite{libdft:2012vee} which is highly optimized/efficient
DFT system runs for binary programs executed from {\tt x86} commodity hardware
system. \libdft provides generic API that helps anybody who want to customize
and build tools that serve for their own problem domains.\jikk{DTA is an
examplary implementation that we implemented with \libdft and we can definitely
have more of this kind}.
%
It is implemented via inlining DFT logic for individual {\tt x86} instructions
\jikk{which would deliver meta-information (\ie taintedness for DFT) from one
operand to another } levage tools from VM-hypervisor layer. For
instrumentation, we employed PIN dynamic binary instrumentation~(DBI)
framework. High efficiency of \libdft achieved by correctly understanding the
structural limitations of DBI-based inlining approaches. \libdft addresses this
issues by introducing optimal tracking codes customized for different types of
{\tt x86} instructions to avoids aforementioned issues. Examples of these
issues include i) the cost required for context switching between the target
application and DBI/analysis contexts ii) Design and efficient management of
shadow memory area and so on. 
%
Evaluation result showed $\sim$10$\times$ - $\sim$11$\times$ slowdown over the
native execution for a number of standard benchmark suites and this was a
significant performance improvement over previous DFT implementations by the
time we introduced the system.\jikk{more justification needed for this
statement}

% TFA (Taint Flow Algebra)
\subsubsection*{\TFAFull: Representation for compiler and DFT-specific optimizations}
The immediate follow-up work is \TFAFull~(\TFA)~\cite{tfa:2012ndss} which
indicates a specially designed IR(intermediate representation) that represents
DFT tracking logics extracted from the original program binary.  Number of
compiler optimization techniques as well as DFT specific ones are applied to
\TFA. Then the optimization result is inserted back to the original program. 
%
Even with the highly crafted/customized tracking logics that we invented for
\libdft, it is not yet close to the optimal and suffers from a good deal of
overhead which hinders DFT system's adaptation to production systems. We could
identify two fundamental the sources of in-optimality\jikk{?} inherent to all
previous DFT implementations including ours. These are about lacking in
understandings about {\it i)} global context of DFT tracking {\it ii)} DFT
semantics which is clearly different from that of the original execution
semantics.
%
To address these issues, we developed the system that is composed of two
different components. The one is for the static analysis to prepare the
optimized tracking logics from dedicated off-line/analysis phase and the other
is for dynamic runtime that enforces optimized DFT logics to the original
program \jikk{that we want to analyze or protect} at runtime.
%
As a result, TFA could achieve \(\sim\)~2\(\times\) performance improvement
over  our baseline tool(\libdft) when it is evaluated against the same set of
standard benchmark suites without compromising the correctness~\footnote{In
        this context, by {\it correctness}, we want to ensure the same level of
security guarantees that the baseline tool \libdft can provide.} of DFT
operations.

% ShadowReplica 
\subsubsection*{\SR: System for parallelized execution of DFT analysis} 
%
Given that \TFA decouples/separates DFT logics from the original program
execution logics for optimization, \SR~\cite{sreplica:2013ccs} project extends
this approach a step further to gain more performance improvement by running
two different contexts from two different cores(CPUs). 
%
Of course, we are not the first one were who are aligned toward the direction
of parallelized analysis, but the many of previous proposals failed to achieve
expected performance gain mostly due to the high communication overhead
connecting the original program execution and DFT analysis context.
Oftentimes, the cost for communication overwhelms the parallelization benefit
and it results in requiring too much of resources to make the system suitable
for online deployment. 
%
The main contribution of \SR project lies in inventing a system that defends
against malicious activities at runtime by directly addressing the issue of
high communication overhead. Different from previous proposals, the system only
requires a single analysis thread per an application thread and its analysis
thread which eventually executes DFT logic represented in \TFA runs about the
same or faster than the application thread resulting in making synchronization
easier between these two different contexts.
%
In \SR project, we again take advantage of static analysis  {\it i)} to have
DFT logic extracted from the target binary and represent them in \TFA
representation and {\it ii)} to minimize the volume and frequency requirement
of data transfers. As seen from \TFA, \SR also ensures the same of
security/correctness guarantees as our baseline tool provides.
%
\SR system again improves the overhead about $\sim$2$\times$, $\sim$4$\times$
over our previous DFT implementations of \TFA and \libdft respectively,
achieving $\sim$2.75$\times$ slowdown over the native execution.
%
As an interesting side effect, even though it uses two CPUs to improve its
response time, \SR consumes the same or less amount of CPU cycles than that of
comparable in-lined DFT implementation~(in our case \TFA) to perform the same
DFT analysis. \jikk{The size of \SR's instrumentation for relevant event
collection is smaller than that of in-lined DFT analysis. With smaller sized
analysis code, underlying DBI framework reduce the amount CPU cycles required
for the context switch.}

%What is the contribution from this line of work -- high level perspectives
\subsubsection*{Contributions}
During my efforts to improve DFT implementations, I could build up in depth
experience with popular research topics of DFT. 
%
To make it closer to real-world deployment, we actively utilized the static
analysis to help/complement the expensive dynamic analysis. 
%
As many of architectural specifics of DFT system are common to different kinds
of dynamic analysis~(\ie Memcheck), we strongly believe that lessons we've
learned from our journey can be applied to other research areas.
 
\subsection*{A research agenda: Accurate and Practical Security System
Architecture}
\jikk{here I need something similar to research statement.}
I will talk about long-term(short term) research agenda and interests.
%
In general interested in 
\subsubsection*{Even more performance}
Even with significant performance improvement that our research could achieve
for DFT systems, I should admit that this is not yet close to the level where
industry and research community  consider applicable for a production
deployment.
%
There is even a saying around research communities whenever its overhead
becomes larger than $5\%$ the security system would not be adapted as a
production system.~\cite{ccs2013:invited_talk}
%
Two major overhead sources that we identified are {\it i)} the the cost for
VM-based instrumentation and {\it ii)} the cost for shadow memory area
management ~(occurs when it translates real address to it counter-part shadow
address).
%
Currently, I have two different approaches to address these issues. The one is
about dedicating a specially designed hardware component to assist parallel
execution of \SR and the other is about proposing an instrumentation framework
that combines compiler-based and binary-only instrumentation frameworks which
so as to maximize the allowed~(partial) source code accesses.
%
I will briefly discuss about details about each approach.

{\bf Hardware-aided \SR} Although \SR attempted to minimize the size of the
code~(event collector) instrumented to the application, the cost for original
application execution along with instrumented event collector code turned out
to be the biggest source of overall slow-down. Besides this cost, shadow memory
translation performed from analysis thread also incurs high overhead causing
high volume of CPU cache traffics. 
%
I want to propose a system the addresses both issues by introducing additional
pipeline stage to log required information and a unit for the address
translation. The important design goal for this project is to make hardware
assistance essential and minimal so as it can also be used to implement other
analysis tools besides DFT by modifying software counterpart.

{\bf A Framework for Hybrid Instrumentation} In contrast to the previous idea,
this is a software only system that proposes a new instrumentation framework
that aims to maximize the benefit of available source access without loosing
complete support for any of execution environment. This approach introduced
number of interesting challenges such as supporting uniform interface that
encompasses compiler~(LLVM) pass based instrumentation and  DBI~(DynamoRIO)
based instrumentation and managing two different instrumentation context from a
single execution unit.  
\subsubsection*{DFT accuracy}
Although DFT has gained many attentions from research communities for its
effectiveness, its correctness in terms of false positives(FPs) or false
negatives(FNs) has not been studied with cares. From this project, we want to
tackle the issue of correct and sound tainting with existing DFT
implementations. Fo this, we implemented taintedness measurement framework
along with input generation system that extend symbolic blackbox fuzzing
approach.

% Some other research areas that I'm interested in. 
\subsection*{Other research interests} 
%
\subsubsection*{Dynamic Binary
Instrumentation (DBI)} In many DFT implementation including ours, VM-based
instrumentation becomes a important medium required for in-lining custom
analysis and often becomes the major source of performance slowdown. 
%
In this projects, we aim to produce a survey report that compares three most
popular DBI implementations(PIN~\cite{}, Valgrind~\cite{}, DynamoRIO~\cite{})
with our own metrics of {\it i)} efficient {\it ii)} usability and {\it iii}  
capability.

\subsubsection*{Software fuzzing}

Deeply interested in number of different static analysis techniques that would
help building reliable software systems. Both white-box~(with source access),
black-box(without access to source code). Symbolic execution and formal
verification techniques.

\subsubsection*{Integer errors} 

For programs written in integer error is notorious for its trickiness to be
correct and write integer error free code. Even thought the problem has long
been around, no one could come up with the complete solution to this problem
and take a high rank from vulnerability list. 
%
The real trickiness lies not in mechanically detecting integer errors but in
identify the real intention of developer since some of integer errors
(overflow, type conversion etc) planted intentionally to make code achieving
developer's goals.
%
We developed a system integrated DFT system with integer error checking system
to watch/observe for two different kind of information flows {\it i)} the one
that connects the source of untrusted input, and the sink of integer error
point~(integer overflow, sign/unsigned extension, type conversions) {\it ii)}
the other that connects the source of integer error point and the sink of the
argument of sensitive calls(malloc, strcpy, etc.)
% 
This system is built to be compliant(?) to the requirement of IARPA funded
project and it passed phase 1, and phase 2 evaluations which contains $\sim$
300 different integer error cases.

\end{small}
\newpage

%refer to http://sites.stat.psu.edu/~surajit/present/bib.htm
\bibliographystyle{plain}
\bibliography{res}
\end{document}

