\documentclass[letterpaper, 10pt]{article}
\topmargin-2.0cm
 
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{xspace}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

% Color Information from -
% http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/latex_advanced/node13.html

\advance\oddsidemargin-0.65in
\advance\evensidemargin-1.5cm
\textheight9.2in
\textwidth6.75in
\newcommand\bb[1]{\mbox{\em #1}}
\def\baselinestretch{1.05}

\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}

\begin{document}
\thispagestyle{fancy}

% Leave Left and Right Header empty.
\lhead{}
\rhead{}

\renewcommand{\headrulewidth}{0pt} \renewcommand{\footrulewidth}{0pt}
\fancyfoot[C]{\footnotesize
\textcolor{gray}{http://www.cs.columbia.edu/$\sim$jikk/application}}

\pagestyle{fancy}
\lhead{\textcolor{gray}{\it Kangkook Jee}}
\rhead{\textcolor{gray}{\thepage /\pageref{LastPage}}}

%Macros of my own
\def\libdft{libdft\xspace}
\def\TFAFull{Taint Flow Algebra\xspace}
\def\TFA{TFA\xspace}
\def\SR{ShadowReplica\xspace}
\def \ie{i.e.,\xspace}

\newif \ifcomments
\commentstrue

\ifcomments
\newcommand{\jikk}[1]{{---\textcolor{red}{#1}---}}
\else
\newcommand{\jikk}[1]{}
\fi
%

% This kind of makes 10pt to 9 pt.
\begin{small}

%\vspace*{0.1cm}
\begin{center}
{\LARGE \bf RESEARCH STATEMENT}\\
\vspace*{0.1cm}
{\normalsize Kangkook Jee (jikk@cs.columbia.edu)}
\end{center}
%\vspace*{0.2cm}

%\begin{document}
%\centerline {\Large \bf Research Statement for Kangkook Jee}
%\vspace{0.5cm}

% Write about research interests...
%\footnotemark
%\footnotetext{Check This}

% Say that research work has been both theoretical and practical.
My long-term research interest lies in {\it i)} building security systems that
protect/harden unknown software program making it immune to software failures
caused either by active exploitation of malicious attackers or by invocation of
unintended developer bugs and {\it ii)} making these technologies practical,
suitable for production deployment by addressing the issue of high overhead.
%
To achieve the goal of building reliable software and make it practical, I
leverages recent innovations from different software substrates. Specifically,
I have been interested in combining static and dynamic analysis techniques to
serve for a single goal of the practical security system. 
%
My main research contributions are concretized over past a few year as I
developed and improved well-known security system of data flow tracking~(DFT).
Although my research have focused on a specific system, I believe the
wisdom/insight that learned from it can still benefit the area of system
security in general since DFT share many architectural characteristics with
else security architectures.  
%
Besides DFT and the same family of security solution, I am also interested in
other techniques related to software reliability which include
whitebox/blackbox fuzzing and building a system that defends against integer
error. 

\subsection*{Data Flow Tracking(DFT) System Innovations} 
% Paragraph 1: A brief paragraph sketching the overarching thematics and topic
% of your research, situating it disciplinary.
%
DFT has been my main research topic which I extensively explored various
aspects of DFT system for its effectiveness in serving many different areas of
research~\cite{libdft:2012vee, tfa:2012ndss, sreplica:2013ccs} as well as
making it efficient so that it can more be adopted by users who want to use the
technology.
%
Typical DFT system composed of three different operations {\it i)} tagging
input variables come in though any untrusted sources {\it ii)} propagating tag
values associated to variables along with program executions {\it iii)}
checking for unintended usages of tagged data/variable. Our implementation
injects these operations using VM-based instrumentation framework so that DFT
can be applied to COTS binaries.
%
Besides implementing DFT system that correctly operates, I invented number of
optimizations to alleviate its high overhead which is known to be inherent to
DFT and systems of the same family which is regarded as my main research
contribution.

% libdft
\subsubsection*{\libdft: High performance fine-grained DFT system for COTS binaries}

\libdft~\cite{libdft:2012vee} is our initial prototype for high performance DFT
system of byte granularity that works for {\it x86} binaries. 
%
It supports generic API that enables users to customize and build tools that
serve for their own demands. 
%
It is implemented by injecting DFT logic for individual taint-propagating
instructions leveraging VM-based instrumentation framework. 
%
Key to \libdft's performance improvement lies in understanding precise
definition of taint propagation semantics for {\it x86} instruction set as well
as the structural limitations of VM instrumentation layer. \libdft  addresses
these issues by introducing optimal tracking codes customized for different
types of instructions to avoids aforementioned issues. Specific considerations
that we made for the implementation include {\it i)} minimization of the cost
required for context switching between the target application and DBI/analysis
contexts {\it ii)} design and efficient management of shadow memory area and so
on. 
%
Evaluation for the prototype shows $\sim$10$\times$ - $\sim$11$\times$
slowdown over the native execution for a number of standard benchmark suites
and this was a significant performance improvement over previous DFT
implementations by the time we introduced the system.\jikk{more justification
needed for this statement}

% TFA (Taint Flow Algebra)
\subsubsection*{Principled Optimizations for DFT}

\TFAFull~(\TFA)~\cite{tfa:2012ndss} is a specially designed IR(intermediate
representation) that captures DFT tracking logics extracted from the original
program binary. Against this representation, we apply number of compiler
optimization techniques as well as DFT specific ones.
%
Even with the highly crafted/customized tracking logics that we invented for
\libdft, it is not yet close to the optimal and suffers from a good deal of
overhead which hinders DFT system's adaptation to production systems. We could
identify two fundamental the sources of in-optimality\jikk{?} inherent to all
previous DFT implementations including ours. These are about lacking in
understandings about {\it i)} global context of DFT tracking {\it ii)} DFT
semantics which is clearly different from that of the original execution
semantics.
%
To address these issues, we developed the system that is composed of two
different components. The one is for the static analysis to prepare the
optimized tracking logics from dedicated off-line/analysis phase and the other
is for dynamic runtime that enforces optimized DFT logics to the original
program \jikk{that we want to analyze or protect} at runtime.
%
As a result, TFA could achieve \(\sim\)~2\(\times\) performance improvement
over  our baseline tool(\libdft) when it is evaluated against the same set of
standard benchmark suites without compromising the correctness~\footnote{In
        this context, by {\it correctness}, we want to ensure the same level of
security guarantees that the baseline tool \libdft can provide.} of DFT
operations.

% ShadowReplica 
\subsubsection*{\SR: System for parallelized execution of DFT analysis} 
%
Given that \TFA decouples/separates DFT logics from the original program
execution logics for optimization, \SR~\cite{sreplica:2013ccs} project extends
this approach a step further to gain more performance improvement by running
two different contexts from two different cores(CPUs). 
%
Of course, we are not the first one were who are aligned toward the direction
of parallelized analysis, but the many of previous proposals failed to achieve
expected performance gain mostly due to the high communication overhead
connecting the original program execution and DFT analysis context.
Oftentimes, the cost for communication overwhelms the parallelization benefit
and it results in requiring too much of resources to make the system suitable
for online deployment. 
%
The main contribution of \SR project lies in inventing a system that defends
against malicious activities at runtime by directly addressing the issue of
high communication overhead. Different from previous proposals, the system only
requires a single analysis thread per an application thread and its analysis
thread which eventually executes DFT logic represented in \TFA runs about the
same or faster than the application thread resulting in making synchronization
easier between these two different contexts.
%
In \SR project, we again take advantage of static analysis  {\it i)} to have
DFT logic extracted from the target binary and represent them in \TFA
representation and {\it ii)} to minimize the volume and frequency requirement
of data transfers. As seen from \TFA, \SR also ensures the same of
security/correctness guarantees as our baseline tool provides.
%
\SR system again improves the overhead about $\sim$2$\times$, $\sim$4$\times$
over our previous DFT implementations of \TFA and \libdft respectively,
achieving $\sim$2.75$\times$ slowdown over the native execution.
%
As an interesting side effect, even though it uses two CPUs to improve its
response time, \SR consumes the same or less amount of CPU cycles than that of
comparable in-lined DFT implementation~(in our case \TFA) to perform the same
DFT analysis. \jikk{The size of \SR's instrumentation for relevant event
collection is smaller than that of in-lined DFT analysis. With smaller sized
analysis code, underlying DBI framework reduce the amount CPU cycles required
for the context switch.}


\subsection*{Research Agenda: Accurate and Practical Security System
Architecture} 
%
I am interested in the area of the system security in general that serve for
enhancement of software system reliability and I have earned in depth knowledge
about a number of technologies help me achieving the goal throughout my
research career. 
%
The followings are research topics that I am currently working on or keeping as
long-term items. This will help you have a flavor of what I have in my mind as
a research vision or agenda. 
%
\subsubsection*{Overhead is still too high} 
%
Even with the meaningful amount of performance improvement that our research
could achieve for DFT systems, I should admit that we have not yet reached the
level where industry and research community would agree it is adoptable. 
% - the following may be redundant.
There is a consensus around research communities that whatever benefit the
security system would bring to its users, $5\%$ overhead is a threshold that
would prevent the system being adapted as a production
system.~\cite{ccs2013:invited_talk}
%
For most in-lining security systems including DFT systems, I could pin down two
major overhead sources; {\it i)} the cost for VM-based instrumentation and {\it
ii)} the cost for shadow memory management ~(mainly occurs as it translates
real address to it counter-part shadow address).
%
Currently, I have two proposals to address these issues. The one resorts to aid
from hardware component and the other is a software only approach that
introduces a new concept of hybrid instrumentation framework. 

%designed hardware component to assist parallel execution of \SR and the other
%is about proposing an instrumentation framework that combines compiler-based
%and binary-only instrumentation frameworks which so as to maximize the
%allowed~(partial) source code accesses.
%%
%I will briefly discuss about details about each approach.
%

{\bf Hardware-aided \SR} Although \SR minimizes the size of the code
instrumented, the cost for original application execution along with
instrumented code (event collector) still takes up the large portion of
slowdown.  Besides this, shadow memory translation done from analysis thread
also accounts for slowdown due to high volume of traffics for shared CPU
caches. 
%
Currently, I am working on a system the addresses these issues by introducing
another pipeline stage that records required information and transfer it to
another core which would eventually replace the in-lined event collector and
communication channel. Another component we are implementing is a new
instruction help performs real-to-shadow address translation. The important
design criteria for this project is to make additional hardware minimal and
flexible so as it can also be used to other analysis tools other than DFT by 
simply modifying its software counterpart.

{\bf A Framework for Hybrid Instrumentation} In contrast to hardware-aided \SR,
it is a software only system that proposes a new instrumentation framework that
maximize the benefit of allowed(partial) source access still supporting
binaries come with no source access. 
%
This hybrid approach introduced number of interesting research questions which
include supporting uniform interface that encompasses compiler~(LLVM) pass
based instrumentation and  DBI~(DynamoRIO) based instrumentation and managing
two different instrumentation context from a single execution unit. 
%
Intuition behind this idea is that in many\jikk{or most} cases, we at least
have access to partial access to the source of the entire execution environment
although it is not complete. I believe that once we implement it correctly, not
only DFT systems but also many other security mechanism will be benefited from
this.

\subsubsection*{Evaluation framework the soundness of DFT systems} 
%
Although DFT has gained many attentions from research communities for its known
effectiveness, its soundness issue in terms of correct information flow has not
been explored thoroughly and the question of errors(false positives or false
negatives) remains unanswered. From this project, we introduce a new
methodology that evaluates the soundness of DFT systems and  a prototype that
implements the methodology.
%
The entire frameework composed of two sub-compoents of {\it i)} taintedness
measurement component that evaluates individual information flow for its
correctness and {\it ii)} input generation system that guides the measurement
component by the approach of symbolic execution.
%
We are planning to apply the methodology to evalute number of different DFT
systems implemented for Android operating system.

%What is the contribution from this line of work -- high level perspectives
\subsubsection*{Contributions}
During my efforts to improve DFT implementations, I could build up in depth
experience with popular research topics of DFT. 
%
To make it closer to real-world deployment, we actively utilized the static
analysis to help/complement the expensive dynamic analysis. 
%
As many of architectural specifics of DFT system are common to different kinds
of dynamic analysis~(\ie Memcheck), we strongly believe that lessons we've
learned from our journey can be applied to other research areas.
 
% Some other research areas that I'm interested in. 
\subsection*{Other research interests} 
%
Besides DFT, I am interested in number of research topics which related to
system reliability in a broader sense.

\subsubsection*{A Comparison Study of Dynamic Binary Instrumentation(DBI)
frameworks}
%
In this project, we perform comparison study that investigates various aspects
of three different Dynamic Binary Instrumentation(DBI) frameworks. Oftentimes,
one of these becomes system security researcher's choice for instrumentation
framework to inline monitoring logic against unknown binaries. Currently,
target frameworks for our study include PIN, DynamoRIO, and Valgrind. These
three frameworks are the most representative DBI frameworks actively maintained
by research communities. As their behavioral and performance implications
significantly differ by each one's design philosophy and intended problem
domain, we want to empirically evaluate them using criteria listed below.

\begin{itemize}
        \item {\bf Userability:} the framework's learning curve, the framework's
           user-friendliness of API, Supports from developer community 
   \item {\bf Effectiveness/Capability:} framework's ability to instrument and
            manipulate the target software provided without compromising the
            execution transparency.  
    \item {\bf Efficiency:} performance overhead of the framework when it instruments
    the target software.  
\end{itemize}

%\subsubsection*{Software fuzzing}
%
%Deeply interested in number of different static analysis techniques that would
%help building reliable software systems. Both white-box~(with source access),
%black-box(without access to source code). Symbolic execution and formal
%verification techniques.

\subsubsection*{Integer errors} 

For programs written in integer error is notorious for its trickiness to be
correct and write integer error free code. Even thought the problem has long
been around, no one could come up with the complete solution to this problem
and take a high rank from vulnerability list. 
%
The real trickiness lies not in mechanically detecting integer errors but in
identify the real intention of developer since some of integer errors
(overflow, type conversion etc) planted intentionally to make code achieving
developer's goals.
%
We developed a system integrated DFT system with integer error checking system
to watch/observe for two different kind of information flows {\it i)} the one
that connects the source of untrusted input, and the sink of integer error
point~(integer overflow, sign/unsigned extension, type conversions) {\it ii)}
the other that connects the source of integer error point and the sink of the
argument of sensitive calls(malloc, strcpy, etc.)
% 
This system is built to be compliant(?) to the requirement of IARPA funded
project and it passed phase 1, and phase 2 evaluations which contains $\sim$
300 different integer error cases.

\end{small}
\newpage

%refer to http://sites.stat.psu.edu/~surajit/present/bib.htm
\bibliographystyle{plain}
\bibliography{res}
\end{document}

