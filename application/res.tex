\documentclass[letterpaper, 10pt]{article}
\topmargin-2.0cm
 
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{xspace}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

% Color Information from -
% http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/latex_advanced/node13.html

\advance\oddsidemargin-0.65in
\advance\evensidemargin-1.5cm
\textheight9.2in
\textwidth6.75in
\newcommand\bb[1]{\mbox{\em #1}}
\def\baselinestretch{1.05}

\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}

\begin{document}
\thispagestyle{fancy}

% Leave Left and Right Header empty.
\lhead{}
\rhead{}

\renewcommand{\headrulewidth}{0pt} \renewcommand{\footrulewidth}{0pt}
\fancyfoot[C]{\footnotesize
\textcolor{gray}{http://www.cs.columbia.edu/$\sim$jikk/application}}

\pagestyle{fancy}
\lhead{\textcolor{gray}{\it Kangkook Jee}}
\rhead{\textcolor{gray}{\thepage /\pageref{LastPage}}}

%Macros of my own
\def\libdft{libdft\xspace}
\def\TFAFull{Taint Flow Algebra\xspace}
\def\TFA{TFA\xspace}
\def\SR{ShadowReplica\xspace}
\def \ie{i.e.,\xspace}

\newif \ifcomments
\commentstrue

\ifcomments
\newcommand{\jikk}[1]{{---\textcolor{red}{#1}---}}
\else
\newcommand{\jikk}[1]{}
\fi
%

% This kind of makes 10pt to 9 pt.
\begin{small}

%\vspace*{0.1cm}
\begin{center}
{\LARGE \bf RESEARCH STATEMENT}\\
\vspace*{0.1cm}
{\normalsize Kangkook Jee (jikk@cs.columbia.edu)}
\end{center}
%\vspace*{0.2cm}

%\begin{document}
%\centerline {\Large \bf Research Statement for Kangkook Jee}
%\vspace{0.5cm}

% Write about research interests...
%\footnotemark
%\footnotetext{Check This}

% Say that research work has been both theoretical and practical.
My main research interest is about protecting/hardening software systems
against malicious attempts from attackers or gaining more reliability against
unintended software bugs leveraging the latest research innovations. Recently,
these innovations are invented from both areas of static and dynamic program
analyses and my research interest lies in combining those two different
research directions so that can serve/complement one another making the
technology more practical in serving for many real world scenarios.

\subsection*{Background and Current Work}
% Paragraph 1: A brief paragraph sketching the overarching thematics and topic
% of your research, situating it disciplinary.
%
In my research history, I extensively explored various aspects of Data Flow
Tracking(DFT) for its effectiveness in serving many different areas of
research~\cite{libdft:2012vee, tfa:2012ndss, sreplica:2013ccs} as well as
making it efficient so that it can more be adopted by users who are in need to
protect their systems.

%
To improve performance of the technology, which incurs prohibitive amount
overhead especially when it is applied to binaries, I developed and utilized
number of static program analysis technologies so that we can make DFT suitable
in many real world scenarios.
% 
For this, my interested research area includes instrumentation schemes
leveraging virtualization layer and static program analyses for many different
substrates which include compiler techniques for programming language
representations and binary analysis.
%
Besides DFT, my research interest spans number of different topics which are
aligned to serve for software security and reliability.
%
\subsubsection*{DFT systems} 
\jikk{explain a bit of DFT system basics}

% libdft
With respect to the number of DFT related research outputs, we first
implemented \libdft~\cite{libdft:2012vee} which is highly optimized/efficient
DFT system runs for binary programs executed from {\tt x86} commodity hardware
system. \libdft provides generic API that helps anybody who want to customize
and build tools that serve for their own problem domains.\jikk{DTA is an
examplary implementation that we implemented with \libdft and we can definitely
have more of this kind}.
%
It is implemented via inlining DFT logic for individual {\tt x86} instructions
\jikk{which would deliver meta-information (\ie taintedness for DFT) from one
operand to another } levage tools from VM-hypervisor layer. For
instrumentation, we employed PIN dynamic binary instrumentation~(DBI)
framework. High efficiency of \libdft achieved by correctly understanding the
structural limitations of DBI-based inlining approaches. \libdft addresses this
issues by introducing optimal tracking codes customized for different types of
{\tt x86} instructions to avoids aforementioned issues. Examples of these
issues include i) the cost required for context switching between the target
application and DBI/analysis contexts ii) Design and efficient management of
shadow memory area and so on. 
%
Evaluation result showed $\sim$10$\times$ - $\sim$11$\times$ slowdown over the
native execution for a number of standard benchmark suites and this was a
significant performance improvement over previous DFT implementations by the
time we introduced the system.\jikk{more justification needed for this
statement}

% TFA (Taint Flow Algebra)
The immediate follow-up work is \TFAFull~(\TFA)~\cite{tfa:2012ndss} which
indicates a specially designed IR(intermediate representation) that represents
DFT tracking logics extracted from the original program binary.  Number of
compiler optimization techniques as well as DFT specific ones are applied to
\TFA. Then the optimization result is inserted back to the original program. 
%
Even with the highly crafted/customized tracking logics that we invented for
\libdft, it is not yet close to the optimal and suffers from a good deal of
overhead which hinders DFT system's adaptation to production systems. We could
identify two fundamental the sources of in-optimality\jikk{?} inherent to all
previous DFT implementations including ours. These are about lacking in
understandings about {\it i)} global context of DFT tracking {\it ii)} DFT
semantics which is clearly different from that of the original execution
semantics.
%
To address these issues, we developed the system that is composed of two
different components. The one is for the static analysis to prepare the
optimized tracking logics from dedicated off-line/analysis phase and the other
is for dynamic runtime that enforces optimized DFT logics to the original
program \jikk{that we want to analyze or protect} at runtime.
%
As a result, TFA could achieve \(\sim\)~2\(\times\) performance improvement
over  our baseline tool(\libdft) when it is evaluated against the same set of
standard benchmark suites without compromising the correctness~\footnote{In
        this context, by {\it correctness}, we want to ensure the same level of
security guarantees that the baseline tool \libdft can provide.} of DFT
operations.

% ShadowReplica 
Given that \TFA decouples/separates DFT logics from the original program
execution logics for optimization, \SR project extends this approach a step
further to gain more performance improvement by running two different contexts
from two different cores(CPUs). 
%
Of course, we are not the first one were who are aligned toward the direction
of parallelized analysis, but the many of previous proposals failed to achieve
expected performance gain mostly due to the high communication overhead
connecting the original program execution and DFT analysis context.
Oftentimes, the cost for communication overwhelms the parallelization benefit
and it results in requiring too much of resources to make the system suitable
for online deployment. 
%
The main contribution of \SR project lies in inventing a system that defends
against malicious activities at runtime by directly addressing the issue of
high communication overhead. Different from previous proposals, the system only
requires a single analysis thread per an application thread and its analysis
thread which eventually executes DFT logic represented in \TFA runs about the
same or faster than the application thread resulting in making synchronization
easier between these two different contexts.
%
In \SR project, we again take advantage of static analysis  {\it i)} to have
DFT logic extracted from the target binary and represent them in \TFA
representation and {\it ii)} to minimize the volume and frequency requirement
of data transfers. As seen from \TFA, \SR also ensures the same of
security/correctness guarantees as our baseline tool provides.
%
\SR system again improves the overhead about $\sim$2$\times$, $\sim$4$\times$
over our previous DFT implementations of \TFA and \libdft respectively,
achieving $\sim$2.75$\times$ slowdown over the native execution.
%
As an interesting side effect, even though it uses two CPUs to improve its
response time, \SR consumes the same or less amount of CPU cycles than that of
comparable in-lined DFT implementation~(in our case \TFA) to perform the same
DFT analysis. \jikk{The size of \SR's instrumentation for relevant event
collection is smaller than that of in-lined DFT analysis. With smaller sized
analysis code, underlying DBI framework reduce the amount CPU cycles required
for the context switch.}

%What is the contribution from this line of work -- high level perspectives

During my efforts to improve DFT implementations, I could build up in depth
experience with popular research topics of DFT. 
%
To make it closer to real-world deployment, we actively utilized the static
analysis to help/complement the expensive dynamic analysis. 
%
As many of architectural specifics of DFT system are common to different kinds
of dynamic analysis~(\ie Memcheck), we strongly believe that lessons we've
learned from our journey can be applied to other research areas.
 
\subsection*{Practical Security System Architecture --- A Research Agenda}
Even though my research focus in the past mostly leaned toward the topic of DFT
and related technologies, this contributions and limitations from my experience
can easily generalized to related defense/reliability technologies.

\begin{itemize}
 \item Hardware component
 \item Framework for hybrid instrumentation
 \item Correctness evaluation data flow tracking technologies
\end{itemize}
\end{small}

% Some other research areas that I'm interested in. 
\subsection*{Other research interests} \subsubsection*{Dynamic Binary
Instrumentation (DBI)} In many DFT implementation including ours, VM-based
instrumentation becomes a important medium required for in-lining custom
analysis and often becomes the major source of performance slowdown. 
%
In this projects, we aim to produce a survey report that compares three most
popular DBI implementations(PIN~\cite{}, Valgrind~\cite{}, DynamoRIO~\cite{})
with our own metrics of {\it i)} efficient {\it ii)} usability and {\it iii}  
capability.

\subsubsection*{Software fuzzing}

Deeply interested in number of different static analysis techniques that would
help building reliable software systems. Both white-box~(with source access),
black-box(without access to source code). Symbolic execution and formal
verification techniques.

\subsubsection*{Integer errors} 

For programs written in integer error is notorious for its trickiness to be
correct and write integer error free code. Even thought the problem has long
been around, no one could come up with the complete solution to this problem
and take a high rank from vulnerability list. 
%
The real trickiness lies not in mechanically detecting integer errors but in
identify the real intention of developer since some of integer errors
(overflow, type conversion etc) planted intentionally to make code achieving
developer's goals.
%
We developed a system integrated DFT system with integer error checking system
to watch/observe for two different kind of information flows {\it i)} the one
that connects the source of untrusted input, and the sink of integer error
point~(integer overflow, sign/unsigned extension, type conversions) {\it ii)}
the other that connects the source of integer error point and the sink of the
argument of sensitive calls(malloc, strcpy, etc.)
% 
This system is built to be compliant(?) to the requirement of IARPA funded
project and it passed phase 1, and phase 2 evaluations which contains $\sim$
300 different integer error cases.

\newpage

%refer to http://sites.stat.psu.edu/~surajit/present/bib.htm
\bibliographystyle{plain}
\bibliography{res}
\end{document}

