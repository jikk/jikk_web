\documentclass[letterpaper, 10pt]{article}
\topmargin-2.0cm

        \usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{xspace}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

% Color Information from -
% http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/latex_advanced/node13.html

\advance\oddsidemargin-0.65in
\advance\evensidemargin-1.5cm
\textheight9.2in
\textwidth6.75in
\newcommand\bb[1]{\mbox{\em #1}}
\def\baselinestretch{1.05}

\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}

\begin{document}
\thispagestyle{fancy}

% Leave Left and Right Header empty.
\lhead{}
\rhead{}

\renewcommand{\headrulewidth}{0pt} \renewcommand{\footrulewidth}{0pt}
\fancyfoot[C]{\footnotesize
\textcolor{gray}{http://www.cs.columbia.edu/$\sim$jikk/application}}

\pagestyle{fancy}
\lhead{\textcolor{gray}{\it Kangkook Jee}}
\rhead{\textcolor{gray}{\thepage /\pageref{LastPage}}}

%Macros of my own
\def\libdft{libdft\xspace}
\def\TFAFull{Taint Flow Algebra\xspace}
\def\TFA{TFA\xspace}
\def\SR{ShadowReplica\xspace}
\def \ie{i.e.,\xspace}

\newif \ifcomments
%\commentstrue

\ifcomments
\newcommand{\jikk}[1]{{---\textcolor{red}{#1}---}}
\else
\newcommand{\jikk}[1]{}
\fi
%

% This kind of makes 10pt to 9 pt.
\begin{small}

%\vspace*{0.1cm}
\begin{center}
{\LARGE \bf RESEARCH STATEMENT}\\
\vspace*{0.1cm}
{\normalsize Kangkook Jee (jikk@cs.columbia.edu)}
\end{center}
%\vspace*{0.2cm}

%\begin{document}
%\centerline {\Large \bf Research Statement for Kangkook Jee}
%\vspace{0.5cm}

% Write about research interests...
%\footnotemark
%\footnotetext{Check This}

% Abstract that states about my research theme.  Say that research work has
% been both theoretical and practical.
My long-term research goal lies in {\it i)} building security systems that
would harden unknown software programs by making it immune to software failures
caused either by active exploitation of malicious attackers or unintended
discovery of developer bugs and {\it ii)} making these technologies efficient
and practical by addressing the issue of high overhead.
%
To achieve the goal, I leveraged number of recent research innovations designed
for different software system stacks. Specifically, I have been interested in
combining static and dynamic analysis to address the issue of high overhead.
%
My main research contributions have been concretized over past a few year as I
developed and improved well-known security system of data flow tracking~(DFT).
Although my research have focused on a specific security architecture, I
believe that the insights that I learned can benefit the area of system
security in general since DFT share many architectural characteristics with
other security architectures.
%
Besides DFT and the same family of security solutions, I am also interested in
other techniques related to software reliability which include
whitebox/blackbox fuzzing and building a system that defends against integer
error.

\subsection*{Data Flow Tracking(DFT) System Innovations}
% Paragraph 1: A brief paragraph sketching the overarching thematics and topic
% of your research, situating it disciplinary.
%
DFT has been my main research topic which I extensively explored various
aspects of the technology for its {\it effectiveness} in serving many different
topics of research as well as for its {\it efficiency} in making it more
adopted by production systems.
%
Typical DFT system is composed of three different operations {\it i)} {\it
tagging} input variables come in though any untrusted sources {\it ii)} {\it
propagating} tag values associated to the variables as the program executed
{\it iii)} {\it checking} for unintended usages of tagged variables. Our DFT
implementations injects these operations using VM-based instrumentation
framework, which is PIN Dynamic Binary Instrumentation~(DBI) framework, to
apply the technology to COTS binaries.
%
Besides implementing DFT system that correctly operates, I invented number of
novel optimization and architectures that alleviates its excessive slowdown
which is inherent to DFT for COTS binaries and security systems of the same
kind. And this is what I consider as the main research contribution.

% libdft
\subsubsection*{\libdft: High performance fine-grained DFT system for COTS
software}

\libdft~\cite{libdft:2012vee} is our initial prototype for DFT that propagates
tag values in byte granularity.
%
It supports generic API that enables users to customize and build tools for
their own research/protection purposes and implements process level
protection~(not system-wide) by injecting DFT logic for individual
taint-propagating instructions leveraging VM-based instrumentation framework.
%
Key to \libdft's performance improvement lies in understanding the precise
definition of taint propagation semantics for {\it x86} instruction set as well
as the structural limitations of VM-based instrumentation layer. \libdft
addresses these issues by introducing optimal tracking codes customized for
different types of {\it x86} instructions. Two main considerations that we made
for the implementation are {\it i)} minimization of the cost required for
context switching between the original application and DFT analysis contexts
and {\it ii)} design and efficient management of shadow memory area.
%
Evaluation for the prototype shows $\sim$10$\times$ - $\sim$11$\times$ slowdown
over the native execution for a number of standard benchmark suites and this
was a significant performance improvement over previous DFT implementations by
the time we introduced the system.\jikk{more justification needed for this
statement}

% TFA (Taint Flow Algebra)
\subsubsection*{\TFA: A framework for principled optimizations for DFT}

Even with the highly crafted/customized tracking logics that we invented for
\libdft, its operation still remained sub-optimal for not being able to address
the fundamental limitations common to up-to-date DFT implementations. These are
about lacking in understandings for {\it i)} the global context of DFT
operations and {\it ii)} the semantics of DFT operations which is clearly
different from that of the original program execution.
%
\TFAFull~(\TFA)~\cite{tfa:2012ndss} is a special purpose Intermediate
Representation~(IR) that captures DFT logics extracted from the original {\it
x86} binary. With this representation, we apply number of traditional compiler
optimizations as well as DFT specific optimizations that we developed to
overcome aforementioned limitations.\jikk{Then, if in-line optimized DFT logics
back to the application not compromising any of security guarantees that our
baseline tool would provide.}
%
For this, we developed the framework composed of two sub-components.
The first one is the static analysis component run from dedicated
off-line/analysis phase which prepares the optimized DFT logics specific to the
target applications. The second one is the dynamic runtime component that
enforces optimized DFT operations back to the original program at runtime.
%
% may want to mention about 'feedback loop' connecting two components.
%
As a result, TFA could achieve \(\sim\)~2\(\times\) performance improvement
over  our baseline tool(\libdft) when it is evaluated against the same set of
standard benchmark suites without compromising the correctness~\footnote{In
        this context, by {\it correctness}, we want to ensure the same level of
security guarantees that the baseline tool (\libdft) can provide.} of DFT
operations.

% ShadowReplica
\subsubsection*{\SR: A framework for parallelized execution of DFT}
%
Given that \TFA represents DFT logics extracted from the original program and
to apply number of optimization approaches, \SR~\cite{sreplica:2013ccs} project
extends it further to have more performance gain by running the original
program and the extracted DFT logics from two different cores~(CPUs).
%
Of course, we are not the first one were who are aligned toward the approach of
parallelized DFT analysis, but the most of previous proposals failed to achieve
expected performance improvement mainly due to the high communication overhead
connecting two different execution contexts. Oftentimes, the cost overwhelms
the parallelization benefit by causing to require excessive amount of resources
to make the system suitable for online deployment.
%
The main contribution of \SR lies in addressing the issue of high communication
overhead and proposing a framework  suitable for runtime defense against any
software failures/exploitations. Different from previous proposals, the system
only requires a single additional analysis thread per an application thread and
the analysis thread~(that executes optimized \TFA representation) runs at the
speed of about the same or faster than that of the application thread resulting
in making synchronization between two different contexts easier.
%
In \SR project, we again dedicate static analysis phase {\it i)} to have DFT
logic extracted from the target application binary and represent them in \TFA
{\it ii)} to minimize the volume and frequency of the communication
requirement.
%
Architectural consideration is required for the communication channel design
otherwise it would easily become a performance bottleneck by having two threads
compete for L1/L2 caches.

%
% Communication channel easily became a performance bottleneck if it is
% designed with no in depth knowledges about CPU and its shared caches.
%
% \SR again ensures the same level of security/correctness guarantees as our
% baseline tool.
%
As a result, \SR framework could improve the overhead by $\sim$2$\times$,
$\sim$4$\times$ over \TFA and \libdft respectively when it is evaluated for the
same standard benchmark suites, achieving $\sim$2.75$\times$ slowdown over the
native execution.
%
As an interesting side effect of \SR, even though it utilizes additional CPUs
for better response time, the entire framework consumes the same or less amount
of CPU cycles than that of comparable in-lined DFT implementation~(in this case
\TFA) for equivalent DFT analysis.
%
In this case, the benefit of having smaller instrumented code for event
collection~(when it is compared to that of in-lined DFT analysis) and its
subsequent performance gains for VM-based instrumentation in context management
outran the additional cost required to establish the communication channel
connecting the application and analysis threads.

\subsection*{Research Agenda: Practical and accurate security architecture}
%
My main research interest lies in the area of the system security in general
that serve for enhancement of software system reliability and I have earned in
depth knowledge and insights about a number of technologies throughout my
research career.
%
The followings are research topics that I am currently working on or keeping as
future items which would help readers to have better understanding about my
long-term research agenda.
%
\subsubsection*{Mitigation of still too high overhead}
%
Even with the substantial amount of performance improvement that our research
could make for DFT systems, I should admit that we have not yet reached the
level where industry and research community would accept as adoptable to their
productions.
% - the following may be redundant.
%And there is a consensus around research communities that whatever benefit the
%security system would bring to its users, $5\%$ overhead is a threshold that
%would prevent the system being adapted as a production
%system.~\cite{ccs2013:invited_talk}
%
For most of security systems that in-line monitoring logics to COTS binary as
DFT systems do, I could pin down two major overhead sources; {\it i)} the cost
for VM-based instrumentation and {\it ii)} the cost for shadow memory
management ~(mainly occurs as it translates real address to it counter-part
shadow address).
%
Currently, I am working on projects of two different directions to address
these points. The first one resorts to hardware component and the second one
proposes a software only solution by proposing new hybrid instrumentation
framework.

{\bf Hardware-assisted \SR} Although \SR minimizes the size of the code
instrumented, the cost for original application execution along with
instrumented code for event collection still takes up the large portion of the
system's overall slowdown. Second to this, the cost for shadow memory
translation accounts for large portion traffics for calculations and CPU cache
pressures.
%
Currently, We are working on a system the addresses these issues by introducing
another pipeline stage to CPU architecture that records required information
and transfer it to another core which would eventually replace the in-lined
event collector and connecting communication channel. Another component we are
implementing is a new instruction that would perform real-to-shadow address
translation. The important design criteria for this project is to make
additional hardware minimal and flexible so as it can also be general to
support other analysis different from DFT with simply modification its software
counterpart.

{\bf Hybrid instrumentation framework} In contrast to hardware-assisted \SR,
this is a software only approach that proposes a new instrumentation framework
that maximize the benefit of available~(partial) source access still supporting
COTS binaries.
%
This framework is established by applying different schemes of the
compiler-based~(LLVM) instrumentation and VM-based~(PIN DBI) instrumentations
to source code and binary respectively.
%
This hybrid approach introduced number of interesting research questions of
combining two different instrumentation contexts into a single execution unit
and support uniform API interface.
%
Intuition behind this idea is that in most cases, we have partial accesses to
source base and With compiler-based instrumentation, we can implement DFT
system severals of times faster system than using VM-based instrumentation for
COTS binaries.
%
We believe that this approach will benefit not only DFT systems but also many
other system security architectures if we implement it correctly.

\subsubsection*{Evaluation framework the soundness of DFT systems}
%
Although DFT has gained many attentions from research communities for its known
effectiveness, its {\it soundness} issue in terms of correct information flow
has not been explored thoroughly and the question about the existence and
frequency of incorrect flows~(false positives or false negatives) remains
unanswered. From this work, me and number of collaborators introduce a new
methodology to evaluate the soundness of DFT systems and a prototype framework
implementation of the methodology.
%
The entire framework composed of two sub-components of {\it i)} taintedness
measurement component that evaluates different information flows and {\it ii)}
the input generation system that guides the measurement component leveraging
the approach of symbolic execution. \jikk{some more texts needed.}
%
We are planning to apply the methodology to evalute number of different DFT
systems implemented for Android operating system.

% Some other research areas that I'm interested in.
\subsection*{Other research interests}
%
Besides DFT, I am interested in number of research topics also related to
system reliability in a broader sense.

\subsubsection*{A comparison study of DBI frameworks for security applications}
%
Oftentimes, security researchers choose one of the following three Dynamic
Binary Instrumentation~(DBI) frameworks -- PIN, DynamoRIO, and Valgrind -- as
their instrumentation medium when they need to in-line security logic to COTS
binaries.
%
In this project, we carry out a comparison study that investigates various
aspects of these  frameworks. As their behavioral and performance implications
significantly differ by each one's design philosophy and intended problem
domain, we propose number of criteria \jikk{Userability,
Effectiveness/capability, efficiency} to empirically evaluate these frameworks.
%
The goal of the project is to provide a guideline for users to make proper
choice when they need to use DBI that meets for their systems.

\subsubsection*{Runtime integer error detection}

The problem of detection/prevention for integer error for applications written
in C/C++ has long been around but none could come up with complete solution to
clear the entire problem domain yet. 
%
To mechanically detect integer errors by instrumenting application source code
is not a difficult process but to figure out code writer's intention is a
tricky one as the compiler writers and application developers takes advantage
of these error intentionally to speed up their applications.
%
We integrate static and dynamic data flow tracking~(DFT) to a typical integer
error checker to address the issue of false positive~(FP) and false
negative~(FN) specifically. Using DFT, we define relevant {\it source, sink}
pairs that would differentiate errors which would lead to exploitable bugs from
intended practices. One example for the pair can be the place for untrusted
input~(e.g., socket input, keyboard inputs) and a location for arithmetic
operation that triggers an integer error. The other example can be pairs of the
location of integers errors flows into security sensitive places such as
arguments for memory allocation functions.
%
To differentiate exploitable bugs from intended practices, we integrated static
and dynamic DFT systems to a typical integer error checker to watch/observe for
two different kind of information flows {\it i)} a flow that connects the
source of untrusted input, and the sink of integer error arithmetic~(integer
overflow, sign/unsigned extension, type conversions) {\it ii)} a flow that
connects the source of integer error point and the sink of the argument of
sensitive calls~({\tt malloc}, {\tt strcpy}, etc.)

The approach aiming to build a system that can provide defend capability
against integer errors at runtime and it is implemented as a LLVM pass.

%What is the contribution from this line of work -- high level perspectives
\subsection*{Summary}

In the course of my research, I could establish in depth experience about DFT
systems hot system security topics that shares its core characteristics with
many other security system architectures.
%
In effort to make the technology closer to the production deployment, I also
invented number of optimization techniques and frameworks composed of static
and dynamic components that establish feedback loop.
%
My future research plan mainly focuses on improve DFT systems for it efficiency
as well as correctness.
%
Besides DFT, I am also interested in system security topics related to hardening
software systems and make those immune to exploitable defects or unintended bugs. 

\end{small}
%\newpage

%refer to http://sites.stat.psu.edu/~surajit/present/bib.htm
\bibliographystyle{plain}
\bibliography{res}
\end{document}
